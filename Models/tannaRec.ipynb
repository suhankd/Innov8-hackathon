{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# NLP\n",
    "\n",
    "from sklearn.feature_extraction .text import TfidfVectorizer\n",
    "\n",
    "# Processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"../Data/processedData.csv\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,4),max_features=64)\n",
    "X = vectorizer.fit_transform(df['processedMessage'])\n",
    "\n",
    "labelEncoder = LabelEncoder()\n",
    "y = labelEncoder.fit_transform(df['species_group'])\n",
    "y = to_categorical(y,num_classes=12)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1,random_state=16)\n",
    "\n",
    "X_train = X_train.toarray()\n",
    "X_test = X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suhan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "model.add(Dense(units=12, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.1417 - loss: 2.4737 - val_accuracy: 0.2222 - val_loss: 2.4391\n",
      "Epoch 2/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2460 - loss: 2.3931 - val_accuracy: 0.2111 - val_loss: 2.3682\n",
      "Epoch 3/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2352 - loss: 2.2708 - val_accuracy: 0.3333 - val_loss: 2.2877\n",
      "Epoch 4/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3803 - loss: 2.1176 - val_accuracy: 0.3778 - val_loss: 2.1894\n",
      "Epoch 5/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4602 - loss: 1.9602 - val_accuracy: 0.4444 - val_loss: 2.0622\n",
      "Epoch 6/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5115 - loss: 1.8172 - val_accuracy: 0.4444 - val_loss: 1.9407\n",
      "Epoch 7/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5203 - loss: 1.6421 - val_accuracy: 0.4333 - val_loss: 1.8141\n",
      "Epoch 8/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5342 - loss: 1.5236 - val_accuracy: 0.4333 - val_loss: 1.6927\n",
      "Epoch 9/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5658 - loss: 1.3584 - val_accuracy: 0.4111 - val_loss: 1.5937\n",
      "Epoch 10/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6004 - loss: 1.2251 - val_accuracy: 0.3889 - val_loss: 1.5017\n",
      "Epoch 11/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5955 - loss: 1.1193 - val_accuracy: 0.4333 - val_loss: 1.4339\n",
      "Epoch 12/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6282 - loss: 1.0652 - val_accuracy: 0.3889 - val_loss: 1.3835\n",
      "Epoch 13/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5964 - loss: 1.0075 - val_accuracy: 0.3778 - val_loss: 1.3311\n",
      "Epoch 14/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6369 - loss: 0.9414 - val_accuracy: 0.3778 - val_loss: 1.2945\n",
      "Epoch 15/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6044 - loss: 0.9458 - val_accuracy: 0.4111 - val_loss: 1.2672\n",
      "Epoch 16/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5661 - loss: 0.9251 - val_accuracy: 0.4000 - val_loss: 1.2636\n",
      "Epoch 17/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6101 - loss: 0.8711 - val_accuracy: 0.4111 - val_loss: 1.2437\n",
      "Epoch 18/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6294 - loss: 0.8359 - val_accuracy: 0.4111 - val_loss: 1.2318\n",
      "Epoch 19/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5611 - loss: 0.8397 - val_accuracy: 0.4111 - val_loss: 1.2170\n",
      "Epoch 20/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6349 - loss: 0.7770 - val_accuracy: 0.3778 - val_loss: 1.2182\n",
      "Epoch 21/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6177 - loss: 0.8520 - val_accuracy: 0.4222 - val_loss: 1.1924\n",
      "Epoch 22/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5964 - loss: 0.8320 - val_accuracy: 0.4222 - val_loss: 1.1965\n",
      "Epoch 23/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6427 - loss: 0.8024 - val_accuracy: 0.4111 - val_loss: 1.1987\n",
      "Epoch 24/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6486 - loss: 0.7967 - val_accuracy: 0.4222 - val_loss: 1.1873\n",
      "Epoch 25/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6045 - loss: 0.7895 - val_accuracy: 0.4333 - val_loss: 1.1874\n",
      "Epoch 26/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6556 - loss: 0.7440 - val_accuracy: 0.4222 - val_loss: 1.1726\n",
      "Epoch 27/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6035 - loss: 0.8052 - val_accuracy: 0.4000 - val_loss: 1.1683\n",
      "Epoch 28/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6041 - loss: 0.8169 - val_accuracy: 0.4333 - val_loss: 1.1798\n",
      "Epoch 29/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6646 - loss: 0.7268 - val_accuracy: 0.4111 - val_loss: 1.2055\n",
      "Epoch 30/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6442 - loss: 0.7529 - val_accuracy: 0.4111 - val_loss: 1.1877\n",
      "Epoch 31/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6287 - loss: 0.7313 - val_accuracy: 0.4111 - val_loss: 1.1720\n",
      "Epoch 32/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6834 - loss: 0.7410 - val_accuracy: 0.4111 - val_loss: 1.1978\n",
      "Epoch 33/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6264 - loss: 0.7804 - val_accuracy: 0.4000 - val_loss: 1.1830\n",
      "Epoch 34/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6362 - loss: 0.7773 - val_accuracy: 0.4222 - val_loss: 1.1719\n",
      "Epoch 35/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6556 - loss: 0.7139 - val_accuracy: 0.3889 - val_loss: 1.2045\n",
      "Epoch 36/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6484 - loss: 0.7197 - val_accuracy: 0.4222 - val_loss: 1.1930\n",
      "Epoch 37/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6399 - loss: 0.7737 - val_accuracy: 0.4111 - val_loss: 1.1869\n",
      "Epoch 38/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6390 - loss: 0.7188 - val_accuracy: 0.4444 - val_loss: 1.1885\n",
      "Epoch 39/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6331 - loss: 0.7413 - val_accuracy: 0.3778 - val_loss: 1.1889\n",
      "Epoch 40/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6243 - loss: 0.7586 - val_accuracy: 0.4222 - val_loss: 1.1863\n",
      "Epoch 41/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6379 - loss: 0.7396 - val_accuracy: 0.3889 - val_loss: 1.1955\n",
      "Epoch 42/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6208 - loss: 0.7416 - val_accuracy: 0.4111 - val_loss: 1.2059\n",
      "Epoch 43/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6685 - loss: 0.7150 - val_accuracy: 0.3889 - val_loss: 1.2019\n",
      "Epoch 44/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6622 - loss: 0.7114 - val_accuracy: 0.4111 - val_loss: 1.1953\n",
      "Epoch 45/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6255 - loss: 0.7577 - val_accuracy: 0.4111 - val_loss: 1.2045\n",
      "Epoch 46/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6481 - loss: 0.7052 - val_accuracy: 0.4333 - val_loss: 1.2152\n",
      "Epoch 47/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6461 - loss: 0.7043 - val_accuracy: 0.4444 - val_loss: 1.1962\n",
      "Epoch 48/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6670 - loss: 0.7202 - val_accuracy: 0.4222 - val_loss: 1.2142\n",
      "Epoch 49/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6694 - loss: 0.6833 - val_accuracy: 0.4333 - val_loss: 1.2150\n",
      "Epoch 50/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6634 - loss: 0.6958 - val_accuracy: 0.4444 - val_loss: 1.2220\n",
      "Epoch 51/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6767 - loss: 0.6572 - val_accuracy: 0.4444 - val_loss: 1.2198\n",
      "Epoch 52/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6756 - loss: 0.7034 - val_accuracy: 0.4111 - val_loss: 1.2132\n",
      "Epoch 53/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6610 - loss: 0.6836 - val_accuracy: 0.4222 - val_loss: 1.2381\n",
      "Epoch 54/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6366 - loss: 0.6943 - val_accuracy: 0.4444 - val_loss: 1.2136\n",
      "Epoch 55/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6733 - loss: 0.6905 - val_accuracy: 0.4222 - val_loss: 1.2379\n",
      "Epoch 56/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6690 - loss: 0.6927 - val_accuracy: 0.4111 - val_loss: 1.2158\n",
      "Epoch 57/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6438 - loss: 0.6814 - val_accuracy: 0.4889 - val_loss: 1.2280\n",
      "Epoch 58/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6513 - loss: 0.7017 - val_accuracy: 0.4222 - val_loss: 1.2350\n",
      "Epoch 59/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6622 - loss: 0.6828 - val_accuracy: 0.4556 - val_loss: 1.2303\n",
      "Epoch 60/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6888 - loss: 0.6365 - val_accuracy: 0.4333 - val_loss: 1.2504\n",
      "Epoch 61/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6577 - loss: 0.6781 - val_accuracy: 0.4444 - val_loss: 1.2409\n",
      "Epoch 62/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6919 - loss: 0.6680 - val_accuracy: 0.4222 - val_loss: 1.2512\n",
      "Epoch 63/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6603 - loss: 0.6743 - val_accuracy: 0.4556 - val_loss: 1.2528\n",
      "Epoch 64/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6593 - loss: 0.6640 - val_accuracy: 0.4556 - val_loss: 1.2491\n",
      "Epoch 65/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6815 - loss: 0.6734 - val_accuracy: 0.4444 - val_loss: 1.2529\n",
      "Epoch 66/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7195 - loss: 0.6748 - val_accuracy: 0.4556 - val_loss: 1.2480\n",
      "Epoch 67/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6961 - loss: 0.6665 - val_accuracy: 0.4444 - val_loss: 1.2623\n",
      "Epoch 68/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6900 - loss: 0.6606 - val_accuracy: 0.4333 - val_loss: 1.2523\n",
      "Epoch 69/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6769 - loss: 0.6830 - val_accuracy: 0.4444 - val_loss: 1.2623\n",
      "Epoch 70/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7246 - loss: 0.6519 - val_accuracy: 0.4222 - val_loss: 1.2723\n",
      "Epoch 71/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7035 - loss: 0.6177 - val_accuracy: 0.4000 - val_loss: 1.2750\n",
      "Epoch 72/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7217 - loss: 0.6415 - val_accuracy: 0.4667 - val_loss: 1.2733\n",
      "Epoch 73/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7016 - loss: 0.6337 - val_accuracy: 0.4333 - val_loss: 1.2743\n",
      "Epoch 74/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7006 - loss: 0.6640 - val_accuracy: 0.4111 - val_loss: 1.2724\n",
      "Epoch 75/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6880 - loss: 0.6156 - val_accuracy: 0.4667 - val_loss: 1.3020\n",
      "Epoch 76/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6927 - loss: 0.6380 - val_accuracy: 0.4111 - val_loss: 1.2783\n",
      "Epoch 77/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7012 - loss: 0.6385 - val_accuracy: 0.4444 - val_loss: 1.2893\n",
      "Epoch 78/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6900 - loss: 0.6649 - val_accuracy: 0.4889 - val_loss: 1.2935\n",
      "Epoch 79/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6946 - loss: 0.6770 - val_accuracy: 0.4333 - val_loss: 1.3103\n",
      "Epoch 80/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6797 - loss: 0.6613 - val_accuracy: 0.4111 - val_loss: 1.3048\n",
      "Epoch 81/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7234 - loss: 0.6248 - val_accuracy: 0.4556 - val_loss: 1.3090\n",
      "Epoch 82/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7164 - loss: 0.6102 - val_accuracy: 0.4556 - val_loss: 1.3159\n",
      "Epoch 83/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7092 - loss: 0.6023 - val_accuracy: 0.4444 - val_loss: 1.2975\n",
      "Epoch 84/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6911 - loss: 0.6614 - val_accuracy: 0.4222 - val_loss: 1.3336\n",
      "Epoch 85/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6960 - loss: 0.6395 - val_accuracy: 0.4333 - val_loss: 1.3133\n",
      "Epoch 86/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7138 - loss: 0.6140 - val_accuracy: 0.4222 - val_loss: 1.3335\n",
      "Epoch 87/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7402 - loss: 0.6175 - val_accuracy: 0.4778 - val_loss: 1.3260\n",
      "Epoch 88/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7228 - loss: 0.5775 - val_accuracy: 0.4222 - val_loss: 1.3229\n",
      "Epoch 89/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7363 - loss: 0.6158 - val_accuracy: 0.4333 - val_loss: 1.3285\n",
      "Epoch 90/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7136 - loss: 0.6260 - val_accuracy: 0.4444 - val_loss: 1.3412\n",
      "Epoch 91/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7228 - loss: 0.6099 - val_accuracy: 0.4556 - val_loss: 1.3394\n",
      "Epoch 92/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7248 - loss: 0.6103 - val_accuracy: 0.4667 - val_loss: 1.3343\n",
      "Epoch 93/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7571 - loss: 0.5798 - val_accuracy: 0.4333 - val_loss: 1.3602\n",
      "Epoch 94/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7641 - loss: 0.5753 - val_accuracy: 0.4667 - val_loss: 1.3296\n",
      "Epoch 95/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7161 - loss: 0.6113 - val_accuracy: 0.4000 - val_loss: 1.3703\n",
      "Epoch 96/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7426 - loss: 0.5735 - val_accuracy: 0.4333 - val_loss: 1.3773\n",
      "Epoch 97/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7259 - loss: 0.5862 - val_accuracy: 0.4667 - val_loss: 1.3620\n",
      "Epoch 98/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7244 - loss: 0.6041 - val_accuracy: 0.4556 - val_loss: 1.3802\n",
      "Epoch 99/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7078 - loss: 0.5608 - val_accuracy: 0.4778 - val_loss: 1.3636\n",
      "Epoch 100/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7501 - loss: 0.5825 - val_accuracy: 0.4556 - val_loss: 1.3768\n",
      "Epoch 101/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7372 - loss: 0.5554 - val_accuracy: 0.4556 - val_loss: 1.3953\n",
      "Epoch 102/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7402 - loss: 0.5553 - val_accuracy: 0.4778 - val_loss: 1.3945\n",
      "Epoch 103/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7323 - loss: 0.5545 - val_accuracy: 0.4667 - val_loss: 1.4160\n",
      "Epoch 104/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7454 - loss: 0.5698 - val_accuracy: 0.4556 - val_loss: 1.4000\n",
      "Epoch 105/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7432 - loss: 0.5576 - val_accuracy: 0.4667 - val_loss: 1.3883\n",
      "Epoch 106/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7393 - loss: 0.5330 - val_accuracy: 0.4556 - val_loss: 1.4281\n",
      "Epoch 107/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7392 - loss: 0.5864 - val_accuracy: 0.4778 - val_loss: 1.4119\n",
      "Epoch 108/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7453 - loss: 0.5801 - val_accuracy: 0.4667 - val_loss: 1.4120\n",
      "Epoch 109/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7823 - loss: 0.5474 - val_accuracy: 0.4667 - val_loss: 1.4395\n",
      "Epoch 110/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7717 - loss: 0.5469 - val_accuracy: 0.5111 - val_loss: 1.4343\n",
      "Epoch 111/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7891 - loss: 0.4910 - val_accuracy: 0.4333 - val_loss: 1.4319\n",
      "Epoch 112/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8073 - loss: 0.5084 - val_accuracy: 0.4111 - val_loss: 1.4500\n",
      "Epoch 113/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7496 - loss: 0.5402 - val_accuracy: 0.4667 - val_loss: 1.4239\n",
      "Epoch 114/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7937 - loss: 0.5065 - val_accuracy: 0.4222 - val_loss: 1.4564\n",
      "Epoch 115/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7621 - loss: 0.5476 - val_accuracy: 0.4556 - val_loss: 1.4683\n",
      "Epoch 116/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7861 - loss: 0.4989 - val_accuracy: 0.4667 - val_loss: 1.4751\n",
      "Epoch 117/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7621 - loss: 0.5145 - val_accuracy: 0.4889 - val_loss: 1.4573\n",
      "Epoch 118/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8220 - loss: 0.4716 - val_accuracy: 0.4556 - val_loss: 1.4702\n",
      "Epoch 119/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8292 - loss: 0.4717 - val_accuracy: 0.4778 - val_loss: 1.4592\n",
      "Epoch 120/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7737 - loss: 0.5342 - val_accuracy: 0.4556 - val_loss: 1.4654\n",
      "Epoch 121/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7940 - loss: 0.5250 - val_accuracy: 0.4667 - val_loss: 1.4702\n",
      "Epoch 122/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8098 - loss: 0.4505 - val_accuracy: 0.4667 - val_loss: 1.4829\n",
      "Epoch 123/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7826 - loss: 0.5090 - val_accuracy: 0.4333 - val_loss: 1.4828\n",
      "Epoch 124/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8052 - loss: 0.5054 - val_accuracy: 0.4778 - val_loss: 1.5044\n",
      "Epoch 125/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8149 - loss: 0.4728 - val_accuracy: 0.4667 - val_loss: 1.4880\n",
      "Epoch 126/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8101 - loss: 0.4678 - val_accuracy: 0.4333 - val_loss: 1.5279\n",
      "Epoch 127/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8174 - loss: 0.4604 - val_accuracy: 0.4556 - val_loss: 1.5271\n",
      "Epoch 128/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7961 - loss: 0.4644 - val_accuracy: 0.4667 - val_loss: 1.5223\n",
      "Epoch 129/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8307 - loss: 0.4437 - val_accuracy: 0.4667 - val_loss: 1.5164\n",
      "Epoch 130/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8376 - loss: 0.4741 - val_accuracy: 0.4667 - val_loss: 1.5476\n",
      "Epoch 131/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7899 - loss: 0.4931 - val_accuracy: 0.4778 - val_loss: 1.5411\n",
      "Epoch 132/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8411 - loss: 0.4232 - val_accuracy: 0.4556 - val_loss: 1.5395\n",
      "Epoch 133/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7895 - loss: 0.4513 - val_accuracy: 0.4222 - val_loss: 1.5411\n",
      "Epoch 134/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7893 - loss: 0.4683 - val_accuracy: 0.4889 - val_loss: 1.5654\n",
      "Epoch 135/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8109 - loss: 0.4751 - val_accuracy: 0.5000 - val_loss: 1.5664\n",
      "Epoch 136/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7837 - loss: 0.4971 - val_accuracy: 0.4444 - val_loss: 1.5703\n",
      "Epoch 137/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8213 - loss: 0.4411 - val_accuracy: 0.4889 - val_loss: 1.5768\n",
      "Epoch 138/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8367 - loss: 0.4214 - val_accuracy: 0.4889 - val_loss: 1.5629\n",
      "Epoch 139/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8061 - loss: 0.4519 - val_accuracy: 0.4778 - val_loss: 1.6037\n",
      "Epoch 140/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8459 - loss: 0.4130 - val_accuracy: 0.4778 - val_loss: 1.5777\n",
      "Epoch 141/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8306 - loss: 0.4296 - val_accuracy: 0.4556 - val_loss: 1.5818\n",
      "Epoch 142/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8554 - loss: 0.4150 - val_accuracy: 0.4667 - val_loss: 1.6089\n",
      "Epoch 143/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8184 - loss: 0.4091 - val_accuracy: 0.4556 - val_loss: 1.6145\n",
      "Epoch 144/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8510 - loss: 0.4026 - val_accuracy: 0.4889 - val_loss: 1.6148\n",
      "Epoch 145/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8501 - loss: 0.4141 - val_accuracy: 0.4778 - val_loss: 1.6230\n",
      "Epoch 146/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8349 - loss: 0.3945 - val_accuracy: 0.4667 - val_loss: 1.6276\n",
      "Epoch 147/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8549 - loss: 0.3959 - val_accuracy: 0.4889 - val_loss: 1.6299\n",
      "Epoch 148/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8445 - loss: 0.4033 - val_accuracy: 0.4444 - val_loss: 1.6445\n",
      "Epoch 149/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8632 - loss: 0.3891 - val_accuracy: 0.4667 - val_loss: 1.6632\n",
      "Epoch 150/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8416 - loss: 0.3820 - val_accuracy: 0.4778 - val_loss: 1.6489\n",
      "Epoch 151/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8492 - loss: 0.4176 - val_accuracy: 0.4222 - val_loss: 1.6733\n",
      "Epoch 152/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8670 - loss: 0.3741 - val_accuracy: 0.4444 - val_loss: 1.7182\n",
      "Epoch 153/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8651 - loss: 0.3828 - val_accuracy: 0.4444 - val_loss: 1.6924\n",
      "Epoch 154/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8623 - loss: 0.3818 - val_accuracy: 0.4556 - val_loss: 1.6971\n",
      "Epoch 155/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8472 - loss: 0.3954 - val_accuracy: 0.4778 - val_loss: 1.7239\n",
      "Epoch 156/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8456 - loss: 0.3909 - val_accuracy: 0.4444 - val_loss: 1.7338\n",
      "Epoch 157/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8647 - loss: 0.3452 - val_accuracy: 0.4778 - val_loss: 1.7055\n",
      "Epoch 158/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8138 - loss: 0.4158 - val_accuracy: 0.4444 - val_loss: 1.7212\n",
      "Epoch 159/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8641 - loss: 0.3612 - val_accuracy: 0.4556 - val_loss: 1.7428\n",
      "Epoch 160/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8603 - loss: 0.3563 - val_accuracy: 0.4889 - val_loss: 1.7379\n",
      "Epoch 161/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8645 - loss: 0.3850 - val_accuracy: 0.4667 - val_loss: 1.7193\n",
      "Epoch 162/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8687 - loss: 0.3667 - val_accuracy: 0.4889 - val_loss: 1.7324\n",
      "Epoch 163/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8819 - loss: 0.3377 - val_accuracy: 0.5000 - val_loss: 1.7542\n",
      "Epoch 164/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8440 - loss: 0.3610 - val_accuracy: 0.4667 - val_loss: 1.7452\n",
      "Epoch 165/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8667 - loss: 0.3815 - val_accuracy: 0.4667 - val_loss: 1.7636\n",
      "Epoch 166/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8961 - loss: 0.3060 - val_accuracy: 0.4667 - val_loss: 1.7780\n",
      "Epoch 167/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8642 - loss: 0.3655 - val_accuracy: 0.4778 - val_loss: 1.7603\n",
      "Epoch 168/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8746 - loss: 0.3387 - val_accuracy: 0.4444 - val_loss: 1.7792\n",
      "Epoch 169/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8742 - loss: 0.3616 - val_accuracy: 0.4667 - val_loss: 1.7770\n",
      "Epoch 170/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8693 - loss: 0.3416 - val_accuracy: 0.4444 - val_loss: 1.8028\n",
      "Epoch 171/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8752 - loss: 0.3573 - val_accuracy: 0.4333 - val_loss: 1.8183\n",
      "Epoch 172/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8776 - loss: 0.3622 - val_accuracy: 0.4444 - val_loss: 1.8387\n",
      "Epoch 173/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8712 - loss: 0.3267 - val_accuracy: 0.4889 - val_loss: 1.8467\n",
      "Epoch 174/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8748 - loss: 0.3516 - val_accuracy: 0.4778 - val_loss: 1.8154\n",
      "Epoch 175/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8687 - loss: 0.3243 - val_accuracy: 0.4556 - val_loss: 1.8775\n",
      "Epoch 176/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8750 - loss: 0.3509 - val_accuracy: 0.4444 - val_loss: 1.8373\n",
      "Epoch 177/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8729 - loss: 0.3240 - val_accuracy: 0.4778 - val_loss: 1.8521\n",
      "Epoch 178/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8727 - loss: 0.3445 - val_accuracy: 0.4333 - val_loss: 1.9087\n",
      "Epoch 179/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8855 - loss: 0.3584 - val_accuracy: 0.4667 - val_loss: 1.9171\n",
      "Epoch 180/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8936 - loss: 0.3327 - val_accuracy: 0.4667 - val_loss: 1.9137\n",
      "Epoch 181/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8924 - loss: 0.3124 - val_accuracy: 0.4778 - val_loss: 1.9349\n",
      "Epoch 182/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8790 - loss: 0.3279 - val_accuracy: 0.4444 - val_loss: 1.9063\n",
      "Epoch 183/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8886 - loss: 0.3285 - val_accuracy: 0.4778 - val_loss: 1.9425\n",
      "Epoch 184/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8832 - loss: 0.3442 - val_accuracy: 0.4556 - val_loss: 1.9237\n",
      "Epoch 185/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8823 - loss: 0.3244 - val_accuracy: 0.4667 - val_loss: 1.9304\n",
      "Epoch 186/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8867 - loss: 0.2676 - val_accuracy: 0.4444 - val_loss: 1.9601\n",
      "Epoch 187/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8686 - loss: 0.3277 - val_accuracy: 0.4889 - val_loss: 1.9595\n",
      "Epoch 188/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8782 - loss: 0.2956 - val_accuracy: 0.4667 - val_loss: 1.9576\n",
      "Epoch 189/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8865 - loss: 0.3168 - val_accuracy: 0.4778 - val_loss: 1.9761\n",
      "Epoch 190/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8670 - loss: 0.3003 - val_accuracy: 0.4444 - val_loss: 1.9866\n",
      "Epoch 191/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8775 - loss: 0.2946 - val_accuracy: 0.4000 - val_loss: 1.9922\n",
      "Epoch 192/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9069 - loss: 0.2857 - val_accuracy: 0.4111 - val_loss: 2.0099\n",
      "Epoch 193/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9081 - loss: 0.2984 - val_accuracy: 0.3889 - val_loss: 1.9653\n",
      "Epoch 194/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8931 - loss: 0.3046 - val_accuracy: 0.4556 - val_loss: 1.9843\n",
      "Epoch 195/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8913 - loss: 0.2701 - val_accuracy: 0.4444 - val_loss: 2.0208\n",
      "Epoch 196/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8670 - loss: 0.3390 - val_accuracy: 0.4667 - val_loss: 2.0371\n",
      "Epoch 197/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8766 - loss: 0.3084 - val_accuracy: 0.4778 - val_loss: 2.0183\n",
      "Epoch 198/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8806 - loss: 0.2924 - val_accuracy: 0.4556 - val_loss: 2.0510\n",
      "Epoch 199/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9160 - loss: 0.2885 - val_accuracy: 0.4000 - val_loss: 2.0315\n",
      "Epoch 200/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8740 - loss: 0.3269 - val_accuracy: 0.4667 - val_loss: 2.0536\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.80      0.62         5\n",
      "           1       0.33      0.67      0.44         3\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.67      0.50      0.57         4\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.33      0.50      0.40         2\n",
      "           6       0.75      0.38      0.50         8\n",
      "           7       0.62      0.83      0.71         6\n",
      "           8       0.50      0.20      0.29         5\n",
      "           9       0.50      0.60      0.55         5\n",
      "          10       0.67      0.50      0.57         4\n",
      "          11       0.60      0.50      0.55         6\n",
      "\n",
      "    accuracy                           0.52        50\n",
      "   macro avg       0.46      0.46      0.43        50\n",
      "weighted avg       0.56      0.52      0.51        50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suhan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\suhan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\suhan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\suhan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\suhan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\suhan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.fit(X_train, y_train, epochs=200, validation_split=0.2)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_test_classes, y_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
